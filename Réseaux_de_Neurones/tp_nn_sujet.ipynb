{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=https://automatants.cs-campus.fr/images/logo_mini.png width=\"150\">\n"
      ],
      "metadata": {
        "id": "D3H384nl2PQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP Réseaux de Neurones"
      ],
      "metadata": {
        "id": "fp9IXMhq2YE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La formation théorique c'est bien rigolo, mais maintenant à vous de jouer ! Aujourd'hui on crée notre première IA de nos mains qui va détecter des chiffres manuscrits !"
      ],
      "metadata": {
        "id": "Hewxts832vzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Si vous bloquez sur la moindre chose, n'hésitez pas à faire appel à nous, on est là pour ça**\n",
        "\n",
        "**PS : tout le texte précédé d'un \"#\" correspond à une case à compléter/modifier**"
      ],
      "metadata": {
        "id": "MC0IoxdH3Te4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import des librairies"
      ],
      "metadata": {
        "id": "XSsxF1SV3pRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commençons par importer numpy, matplotlib.pyplot, torch, torch.nn (qu'on nommera nn) et torchvision"
      ],
      "metadata": {
        "id": "yPAITYx13vSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "\n",
        "\n",
        "# import\n",
        "# import\n",
        "# import\n",
        "# import\n",
        "# import\n"
      ],
      "metadata": {
        "id": "HEyS0mw54SqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Téléchargement du Dataset"
      ],
      "metadata": {
        "id": "KAlHiyUQ4V2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le premier dataset sur lequel on va entraîner un réseau de neurones est MNIST. Ce sont 60 000 images de chiffres de 0 à 9 en noir et blanc avec leur catégorie/label associé. Elles sont de taille 28x28 et de pixels à valeurs dans [0,255]."
      ],
      "metadata": {
        "id": "TQSOXQ7G4bWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg width=\"300\">"
      ],
      "metadata": {
        "id": "QseWqBMh4i1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code pour télécharger le dataser est déjà fourni. Les images sont normalisées entre 0 et 1 pour votre plus grand plaisir. Il suffit d'exécuter le code fourni"
      ],
      "metadata": {
        "id": "IabzWwa25I0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Load dataset\n",
        "dataloader = torchvision.datasets.MNIST(root = \"\", download=True)\n",
        "train_size = len(dataloader) * 0.8\n",
        "\n",
        "X = np.empty((len(dataloader), 28,28))\n",
        "Y = np.empty(len(dataloader))\n",
        "\n",
        "for i, (image, label) in enumerate(dataloader):\n",
        "    X[i] = image\n",
        "    Y[i] = label\n",
        "\n",
        "X = X / 255\n",
        "\n",
        "X_train = X[:int(train_size)]\n",
        "Y_train = Y[:int(train_size)]\n",
        "\n",
        "X_test = X[int(train_size):]\n",
        "Y_test = Y[int(train_size):]\n",
        "\n",
        "print(\"Donwloaded Mnist Dataset\")\n",
        "print(\"Dataset size : \", len(dataloader))\n",
        "print(f\"Training using {len(X_train)} examples\")\n",
        "print(f\"Testing using {len(X_test)} examples\")"
      ],
      "metadata": {
        "id": "LWnGU9bx5GlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichons quelques images du Dataset pour y voir plus clair"
      ],
      "metadata": {
        "id": "ClGwdm3E5NZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Display data\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(Y_train[i])"
      ],
      "metadata": {
        "id": "pFZxUc555Sy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au final qu'avons nous devons nous ? On a à disposition `X_train`, `Y_train`, `X_test`, `Y_test`\n",
        "Commençons par `X_train` et `X_test`"
      ],
      "metadata": {
        "id": "-39UomPv5Wkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "Vt5RgAI35sDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce qu'on peut remarquer ce que `X_train` contient 48000 examples d'images de taile 28x28\n",
        "`X_train` contient 1200 images de la même taille"
      ],
      "metadata": {
        "id": "a58ZwdIm5ulQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "id": "oOLWVys_51hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour `Y_train` et `Y_test`, nous avons pareil 48000 et 12000 examples mais cette fois on a juste des entiers, cela correspond aux labels. Gardez ça en tête !\n"
      ],
      "metadata": {
        "id": "1ffsduRr58AZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Le Réseau de Neurones"
      ],
      "metadata": {
        "id": "gy9Uagqw6CCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons maintenant commencer le TP ! Comme abordé lors de la première formation, nous allons utiliser les réseaux des neuronnes.\n",
        "\n",
        "Pour cela, nous allons procéder en 4  étapes :  :\n",
        "- On va d'abord définir notre réseau\n",
        "- Puis définir une fonction de perte et une métode d'optimization\n",
        "- Ensuite on pourra lancer l'entrainement,\n",
        "- A la fin, on pourra évaluer notre modèle\n"
      ],
      "metadata": {
        "id": "u214e6pD6H5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition du modèle\n",
        "\n",
        "Nous allons utiliser le module ```Sequential```  de Pytorch. Vous pouvez trouver des informations utiles dans la documentation de Pytorch : https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
        "\n",
        "Essayons d'utiliser le couches ```nn.Linear``` et ```nn.ReLU``` pour reproduire le réseau que nous avons présenté lors de la formation ! N'oubliez pas d'ajouter la softmax à la fin !\n"
      ],
      "metadata": {
        "id": "iIb2GXQ66ewS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "### Compléter la commande avec le réseau qu'on a vu pendant la formation\n",
        "\n",
        "#\n",
        "# model = nn.Sequential(\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "jHLXIog763fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour un petit résumé de notre modèle, appelons le"
      ],
      "metadata": {
        "id": "FHB17Rw5662X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "tjf2xpfG6_AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition de la fonction de perte et de l'optimizer\n",
        "\n",
        "On va utiliser la function `MSELoss` et le optimizer `Adam` (vous pouvez trouver de la documentation ici :https://pytorch.org/docs/stable/optim.html ):"
      ],
      "metadata": {
        "id": "IJt63efJ7Be3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "\n",
        "# loss_function =\n",
        "# optimizer ="
      ],
      "metadata": {
        "id": "5cXr0k0H7KSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Entraînement : préparation\n",
        "\n",
        "Avant de lancer la boucle d'entraînement, il faut préparer un peu le terrain :\n",
        "\n",
        "Rappelez vous que tout d'abord, il fallait \"flatten\" nos images d'entrée de 28*28 à un gros vecteur de taille 784\n",
        "\n",
        "Ensuite, vous pouvez remarquer que les labels que nous avons à notre disposition ne sont pas dans le bon format ! Notre réseau sort un vecteur de probbilités, tandis que les labels dans Y_train sont des entiers. Il faut donc transformer les entiers dans des vecteurs de probabilité. Ceci s'appelle l'encodage one-hot.\n",
        "\n",
        "Exemple :\n",
        "`5` devient` [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] `\n",
        "\n"
      ],
      "metadata": {
        "id": "fJy-gIar7S7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "# On commence par changer la structure de X_train. Nous voulons qqch de la forme (N, 28*28)\n",
        "\n",
        "# X_train_flattened = X_train.reshape(DIMENSION, DIMENSION)"
      ],
      "metadata": {
        "id": "nJS9FQCW7hfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "\n",
        "# Appliquons maintenant un encodage one-hot de Y_train\n",
        "\n",
        "\n",
        "# Encodage one hot\n",
        "# Y_train_onehot =\n",
        "# Y_train_onehot\n",
        "\n",
        "# Visualisons la forme de cette nouvelle matrice\n",
        "\n",
        "Y_train_onehot.shape"
      ],
      "metadata": {
        "id": "sG8pmtDj7k_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous sommes presque prêts à entrainer. La dernière chose qui reste est de transformer nos arrays type numpy aux tensor type Pytorch. L'object tensor est un object spécifique à Pytorch, qui permet de faire des calculs spécifiques au Deep Learning de manière parallèlisée, donc très efficace.\n",
        "Vous pouvez trouver plus des détails sur internet : https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html\n",
        "\n",
        "Pour ce qui nous concerne, nous allons manipuler les tensors comme des arrays numpy"
      ],
      "metadata": {
        "id": "uIAGyn2A756w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant vous allez entrainer votre modèle sur le dataset qui comporte les images (`X_train`) associées à leur label (`Y_train`). Pour cela on utilise la méthode `model.fit(...)`.\n",
        "\n",
        "L'argument epochs correspond au nombre de fois où le dataset est présenté au réseau de neurones. Ici mettez entre 1 et 20 epochs.\n",
        "\n",
        "L'argument validation_data sert à vérifier que votre modèle est bon sur des images qu'il n'a jamais vues (pas utilisées dans l'entrainement), i.e. qu'il n'a pas \"appris\" le dataset par cœur.\n",
        "\n",
        "Documentation : https://www.tensorflow.org/api_docs/python/tf/keras/Model"
      ],
      "metadata": {
        "id": "jhZ8A8ER78m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "# Convertissez vos arrays en tensor, verifiez que le type est bien float32\n",
        "\n",
        "# X_train_torch =\n",
        "# Y_train_onehot_torch ="
      ],
      "metadata": {
        "id": "Zq2xmPjW8Uki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code de vérification du type de vos tensors\n",
        "\n",
        "Y_train_onehot_torch.dtype, X_train_torch.dtype,"
      ],
      "metadata": {
        "id": "dEX1dFz88WNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Entraînement : la boucle"
      ],
      "metadata": {
        "id": "lOz43OGb8Zv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "# epochs = 1\n",
        "\n",
        "\n",
        "# for _ in range(epochs):\n",
        "#     outputs = m # Calculer les predictions du modèle\n",
        "\n",
        "#     loss =  # Calculer la loss\n",
        "\n",
        "#     print(loss)\n",
        "\n",
        "#     optimizer.zero_grad() # Mettre les gradients à 0\n",
        "\n",
        "#     # Faire de la backpropagation\n",
        "#     # Appliquer la formule de mise à jour des poids\n",
        "\n"
      ],
      "metadata": {
        "id": "ftL_S1-58d0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La loss diminue ! C'est encourageant mais vérifions quand même les performances de notre modèle."
      ],
      "metadata": {
        "id": "Ip8QFf-u8ke6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation du modèle\n",
        "\n",
        "Il faut qu'on prépare les `X_test`et `Y_test`de la même manière que pour `X_train`et `Y_train`.\n",
        "On va quand même se simplifier un peu la vie : plutôt que de mettre nos labels de test en one-hot, on va traduire les prédictions en entier."
      ],
      "metadata": {
        "id": "oKVKPtVC81Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "\n",
        "# Commencons par le changement de dimension et la transformation en tensor\n",
        "\n",
        "# X_test_flatten =\n",
        "# X_test_flatten_torch ="
      ],
      "metadata": {
        "id": "24iDHYQQ9Tgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faisons passer `X_test`à travers le réseau et récupérons la sortie"
      ],
      "metadata": {
        "id": "e1Bct3RT9WBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(X_test_flatten_torch)\n",
        "outputs.shape"
      ],
      "metadata": {
        "id": "8sCYcC289c_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformons maintenant les vecteurs de probabilité en entiers"
      ],
      "metadata": {
        "id": "vCAn6m6s9hCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = outputs.argmax(axis=1)"
      ],
      "metadata": {
        "id": "uG-XDG0j9lsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff = predicted_labels - Y_test\n",
        "accuracy = len(diff[diff==0]) / len(diff)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "1YSXtQ0X9ok4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Améliorations possibles\n",
        "\n",
        "Bravo ! Vous avez entrainé votre réseau et évalué votre modèle. Nous allons maintenant essayer d'améliorer un peu votre boucle d'entraînement.\n",
        "\n",
        "D'abord on va entrainer sur plusieurs epochs, donc on veut afficher la loss que périodiqement. Ensuite, il serait intéressant de tracer l'évolution de notre courbe de loss.\n",
        "Finalement, on pourrait aussi evaluer le modèle à chaque fois qu'on calcule la loss pour avoir une idée plus précise de la performance du modèle"
      ],
      "metadata": {
        "id": "Y4Pu7u7C9rbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commençons par les deux premiers points"
      ],
      "metadata": {
        "id": "SpSYvF_L95gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "epochs = 50\n",
        "losses = []\n",
        "\n",
        "# A compléter\n",
        "\n",
        "# for i in range(epochs):\n",
        "    # A vous de jouer !"
      ],
      "metadata": {
        "id": "_t4mlNGU98q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et maintenant, écrivons une fonction `evaluate_model()` qui permet de calculer la précision du modèle (*accuracy*)"
      ],
      "metadata": {
        "id": "QjpE4bnj-Cd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "\n",
        "def evaluate_model(model):\n",
        "    pass\n",
        "    # A vous de jouer !"
      ],
      "metadata": {
        "id": "EA5F1T0F-QmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons tous les éléments maintenant pour créer une bonne boucle d'entraînement. Nous allons redéfinir notre modèle pour initialiser nos poids et commencer table rase (Attention à rédefinir l'optimizer parce que\n",
        "nous avons des nouveaus paramètres maintenant):"
      ],
      "metadata": {
        "id": "1lamfFES-XC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Celulle à compléter ####\n",
        "epochs = 200\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "\n",
        "# model =\n",
        "\n",
        "# loss_function =\n",
        "# optimizer =\n",
        "\n",
        "print(\"Début de l'entraînement\")\n",
        "\n",
        "for i in range(epochs):\n",
        "    # outputs =  # Calculer les predictions du modèle\n",
        "\n",
        "    # loss =  # Calculer la loss\n",
        "    # losses.append(?????)\n",
        "\n",
        "    # optimizer.zero_grad() # Mettre les gradients à 0\n",
        "\n",
        "    # ___________________ # Faire de la backpropagation\n",
        "    # _______________ # Appliquer la formule de mise à jour des poids\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        accuracy = evaluate_model(model)\n",
        "        print(f\"Epoch {i} | Loss : {loss} | Accuracy : {accuracy}\")\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Fin de l'entraînement\")\n",
        "plt.plot(losses)\n",
        "plt.figure()\n",
        "plt.plot(accuracies, \"o\", color=\"red\")"
      ],
      "metadata": {
        "id": "y_ccGS4--b3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dans la littérature, la meilleure accuracy est de 99.87%, à vous de le battre !"
      ],
      "metadata": {
        "id": "tK4wlmTO-hiy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZGW9FAo-1cQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
